{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "PBTbrJXOngz2",
        "Yfr_Vlr8HBkt",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "hwyV_J3ipUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "qBMux9mC6MCf",
        "yiiVWRdJDDil",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "P1XJ9OREExlT",
        "TIqpNgepFxVj",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Yes Bank Stock Closing Price Prediction\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting Yes Bank’s Stock Closing Price: A Strategic Overview\n",
        "\n",
        "Accurately predicting Yes Bank’s stock closing price is a critical tool for businesses and investors, enabling informed decision-making, risk management, and profitability. This process involves leveraging historical data, advanced machine learning models, and a comprehensive understanding of market factors.\n",
        "\n",
        "#### **Importance of Stock Price Prediction**\n",
        "\n",
        "Stock price prediction supports key business activities like portfolio management, strategic planning, and risk mitigation. For Yes Bank, these predictions offer insights into market sentiment, economic shifts, and potential growth opportunities, enhancing overall financial strategy.\n",
        "\n",
        "#### **Data as the Foundation**\n",
        "\n",
        "Robust and relevant data forms the basis of any predictive model. For Yes Bank, this includes historical stock prices, trading volumes, and technical indicators like Moving Averages and RSI. Integrating external factors such as economic indicators and news events ensures a holistic approach, improving prediction accuracy.\n",
        "\n",
        "#### **Data Preprocessing and Model Selection**\n",
        "\n",
        "Preprocessing involves cleaning and normalizing data, while feature engineering creates new variables that highlight trends. Choosing the right machine learning model, whether it’s a simple Linear Regression or a more complex LSTM network, is crucial. LSTM, in particular, excels in handling time-series data, making it ideal for stock price prediction.\n",
        "\n",
        "#### **Business Implementation**\n",
        "\n",
        "After training and validation, the model can be deployed in real-time trading systems, offering daily or weekly predictions. Incorporating confidence intervals helps quantify uncertainty, aiding in more informed decision-making. These predictions support immediate trading decisions and long-term strategic planning, providing a competitive edge in the financial markets.\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "Predicting Yes Bank’s stock price is a strategic initiative that enhances business decision-making, risk management, and profitability. By using advanced machine learning models and comprehensive data, businesses can stay ahead in today’s fast-paced financial environment, making this approach essential for modern financial strategy."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement: Predicting Yes Bank’s Stock Closing Price\n",
        "\n",
        "The financial markets are inherently volatile, and accurately predicting stock prices is a complex challenge that holds significant importance for investors, financial institutions, and businesses. For Yes Bank, a major player in the Indian banking sector, predicting its stock's closing price is crucial for making informed investment decisions, managing risks, and optimizing trading strategies.\n",
        "\n",
        "The key problem is to develop a reliable predictive model that can accurately forecast the daily closing price of Yes Bank’s stock. This requires the integration of historical stock data, technical indicators, and external market factors into a machine learning framework. The model must not only deliver precise predictions but also account for uncertainties in the market to support better risk management and strategic planning.\n",
        "\n",
        "The solution needs to be robust, capable of handling the dynamic nature of financial data, and provide actionable insights that can enhance decision-making processes across various business functions, from investment management to financial reporting.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import missingno as msno\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qT1vJe2eQkBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Copy of data_YesBank_StockPrices.csv\", encoding= 'unicode_escape' )"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "oW5bHtfXTLUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "id": "naOYxI8xJxmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "msno.bar(df,figsize=(6,6))\n",
        "plt.title('Missing Data bar Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From a business perspective, the dataset contains historical stock prices of Yes Bank, including the opening, highest, lowest, and closing prices over time. This data is crucial for analyzing the stock's performance, understanding market trends, and predicting future price movements. Key insights include:\n",
        "\n",
        "1. **Trend Analysis:** The closing prices provide insights into the stock's trend over time, which is essential for making investment decisions.\n",
        "2. **Volatility:** The range between the high and low prices can indicate the stock's volatility, helping in risk assessment.\n",
        "3. **Historical Performance:** The data allows for historical performance analysis, aiding in strategic planning and forecasting.\n",
        "4. **Feature Creation:** Additional indicators (e.g., moving averages) can be derived to enhance predictive models, supporting more informed trading strategies.\n",
        "\n",
        "This dataset is foundational for building predictive models that can guide investment decisions, optimize trading strategies, and manage financial risk."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description\n",
        "Here’s a description of the variables in the dataset, from a business perspective:\n",
        "\n",
        "1. **Date**:\n",
        "   - **Description**: The specific date corresponding to the stock prices.\n",
        "   - **Business Use**: Helps in tracking the temporal progression of stock prices and identifying trends over time.\n",
        "\n",
        "2. **Open**:\n",
        "   - **Description**: The price at which Yes Bank's stock started trading at the beginning of the trading day.\n",
        "   - **Business Use**: Used to gauge the initial market sentiment and compare with the closing price to assess daily stock performance.\n",
        "\n",
        "3. **High**:\n",
        "   - **Description**: The highest price at which Yes Bank's stock traded during the trading day.\n",
        "   - **Business Use**: Indicates the peak market value during the day, useful for understanding intraday volatility.\n",
        "\n",
        "4. **Low**:\n",
        "   - **Description**: The lowest price at which Yes Bank's stock traded during the trading day.\n",
        "   - **Business Use**: Highlights the lowest market valuation during the day, helping assess downside risk and intraday volatility.\n",
        "\n",
        "5. **Close**:\n",
        "   - **Description**: The price at which Yes Bank's stock closed at the end of the trading day.\n",
        "   - **Business Use**: The most critical value for investors, used to evaluate the stock’s daily performance and as a basis for predictive modeling.\n",
        "\n",
        "These variables are essential for performing financial analysis, evaluating market trends, and building predictive models that inform investment strategies and risk management practices."
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft6Eno9AY866"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns.tolist():\n",
        "  print('unique values for each variable in ',i, 'are', df[i].nunique())"
      ],
      "metadata": {
        "id": "ZYj3I26ja2-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df.columns"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Date' column to a proper datetime format\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "df['Date']=pd.to_datetime(df['Date'].apply(lambda x: datetime.strptime(x,'%b-%y')))"
      ],
      "metadata": {
        "id": "BeI6SiX7BvuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "AtzNJW8we50I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Aue5wuCve-N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col=df.columns.to_list()\n",
        "numerical_cols=col[1:]\n",
        "numerical_cols"
      ],
      "metadata": {
        "id": "a_kgkitEfbKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Filling missing values (example: filling with mean)\n",
        "df.fillna(df.mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "kB0X5W7xCmb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the Date as index.\n",
        "df.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "yyMgszN9f2hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "p3OwFNWvgOFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperating the data\n",
        "in_value = df.columns.tolist()[:-1]\n",
        "out_value = ['Close']\n",
        "\n",
        "print(in_value)\n",
        "print(out_value)"
      ],
      "metadata": {
        "id": "lUUGvHIkg60E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[1:186]"
      ],
      "metadata": {
        "id": "2AVQvKhNJb6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulations Performed:\n",
        "\n",
        "1. **Date Conversion**:\n",
        "   - Converted the 'Date' column to a datetime format for proper time series handling.\n",
        "\n",
        "2. **Indexing**:\n",
        "   - Set 'Date' as the index to facilitate time-based operations.\n",
        "\n",
        "3. **Handling Missing Values**:\n",
        "   - Dropped rows with missing data to ensure a clean dataset.\n",
        "\n",
        "4. **Feature Engineering**:\n",
        "   - **Moving Averages**: Added 7-day, 14-day, and 30-day moving averages to capture trends.\n",
        "   - **High-Low Difference**: Created a feature to measure the daily price range.\n",
        "   - **Daily Price Change**: Computed the difference between the closing and opening prices to capture daily price movements.\n",
        "   - **Percentage Change**: Added a feature to track the daily percentage change in the closing price.\n",
        "   - **Lag Features**: Introduced lagged closing prices (previous days) to capture temporal dependencies.\n",
        "\n",
        "5. **Data Normalization**:\n",
        "   - Normalized the 'Close' price using MinMaxScaler to improve model performance.\n",
        "\n",
        "### Insights Found:\n",
        "\n",
        "1. **Trend Analysis**:\n",
        "   - The moving averages (MA7, MA14, MA30) provide insights into short-term and long-term trends in Yes Bank’s stock prices.\n",
        "\n",
        "2. **Volatility Indicators**:\n",
        "   - The High-Low difference and percentage change features offer a measure of daily price volatility.\n",
        "\n",
        "3. **Temporal Dependencies**:\n",
        "   - Lagged features (e.g., Lag1_Close) help in understanding how the previous day's closing prices influence the current day’s price.\n",
        "\n",
        "4. **Data Cleanliness**:\n",
        "   - After handling missing values, the dataset is more reliable for modeling, ensuring that no incomplete data skews the results.\n",
        "\n",
        "These manipulations prepare the dataset for accurate modeling and offer a foundation for deeper analysis and prediction."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Line plot for 'Close','Open' prices over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='Date', y='Close', data=df, label='Close Price', color='b')\n",
        "sns.lineplot(x='Date', y='Open', data=df, label='Open Price', color='c')\n",
        "plt.title('Stock Closing & Opening Prices Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chart 1** (line plot of 'Close' and 'Open' prices over time) is crucial from a business perspective because it provides insights into stock market trends and performance. Here's a summary of its value:\n",
        "\n",
        "1. **Visualizes Market Trends**: Tracks stock price fluctuations over time, helping businesses monitor trends and make informed investment decisions.\n",
        "2. **Compares Open and Close Prices**: Highlights intraday price movements, reflecting market sentiment (positive or negative) during trading hours.\n",
        "3. **Tracks Volatility**: Shows periods of high and low volatility, essential for risk management and strategic planning.\n",
        "4. **Historical Analysis**: Assists in comparing past performance with current conditions for forecasting and strategy adjustments.\n",
        "5. **Supports Stakeholder Decision-Making**: Helps investors and analysts align price changes with market events, aiding in portfolio and asset management.\n",
        "6. **Identifies Market Cycles**: Reveals recurring patterns or cycles, guiding entry and exit points for traders.\n",
        "\n",
        "Overall, this chart offers a clear and essential view of stock performance, aiding in crucial business and investment decisions."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From **Chart 1** (line plot of 'Close' and 'Open' prices over time), the key business insights are:\n",
        "\n",
        "1. **Stock Performance Trends**: The chart shows whether the stock price is generally trending upward or downward, helping businesses assess the stock's long-term potential.\n",
        "   \n",
        "2. **Market Sentiment**: By comparing the opening and closing prices, you can identify **daily market sentiment**—whether the stock tends to gain or lose value throughout the trading day. This can reflect investor confidence or concerns.\n",
        "   \n",
        "3. **Volatility Patterns**: Periods of high fluctuations between the opening and closing prices indicate **increased volatility**, signaling potential risk or opportunities. Stable periods suggest lower risk but may also indicate less opportunity for short-term gains.\n",
        "   \n",
        "4. **Significant Events Impact**: Sudden spikes or drops in prices may correlate with business events such as earnings announcements, product launches, or external market conditions. Understanding these events helps in forecasting future stock behavior.\n",
        "\n",
        "5. **Entry and Exit Timing**: Identifying trends over time can guide investors on when to buy (during dips) or sell (during peaks), making this chart valuable for **investment timing** and portfolio management.\n",
        "\n",
        "In summary, this chart helps businesses and investors make informed decisions about stock investments, understand market sentiment, and manage risk based on performance trends and volatility."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Will the Gained Insights Help Create a Positive Business Impact?\n",
        "\n",
        "Yes, the insights from **Chart 1** can positively impact business by enabling:\n",
        "1. **Informed Investment Decisions**: Helps optimize buy/sell timings for higher profitability.\n",
        "2. **Risk Management**: Identifies volatility to manage portfolio risks.\n",
        "3. **Strategic Timing**: Supports well-timed market entries/exits.\n",
        "4. **Forecasting & Planning**: Guides long-term growth strategies based on trends.\n",
        "\n",
        "### Are There Any Insights That Lead to Negative Growth?\n",
        "\n",
        "Yes, potential indicators of **negative growth** include:\n",
        "1. **Downward Price Trends**: Signals poor performance, reducing investor confidence.\n",
        "2. **High Volatility**: Suggests instability, deterring investors.\n",
        "3. **Negative Sentiment**: Frequent price drops throughout the day indicate doubts about future performance.\n",
        "\n",
        "### Justification for Negative Growth:\n",
        "\n",
        "- **Consistent Price Drops**: Leads to lower market capitalization and growth potential.\n",
        "- **Volatility**: Creates higher investment risk, driving investors away.\n",
        "\n",
        "In short, positive trends support growth, while downward and volatile trends signal risks."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Out variable 'Close'\n",
        "#checking the distribution of the dependent variable\n",
        "plt.figure(figsize=(7,7))\n",
        "\n",
        "sns.distplot(df['Close'], color=\"b\")\n",
        "plt.title('Distribution of Out variable')\n",
        "plt.xlabel('Closing Price')\n",
        "\n",
        "plt.axvline(df['Close'].mean(), color='yellow', label='Mean')\n",
        "plt.axvline(df['Close'].median(), color='red', linestyle='dashed', label='Median')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart you picked, which is a distribution plot (or histogram with a kernel density estimate), is useful for several reasons:\n",
        "\n",
        "1. **Visualizing Distribution**: It shows how the 'Close' values are distributed across different ranges. This helps in understanding the spread, central tendency, and skewness of the data.\n",
        "\n",
        "2. **Identifying Skewness**: By visualizing the distribution, you can identify whether the data is skewed to the left or right, or if it follows a normal distribution.\n",
        "\n",
        "3. **Highlighting Central Tendency**: The vertical lines for mean and median provide clear markers for the central tendency of the data, helping to understand where most values lie and how they compare.\n",
        "\n",
        "4. **Detecting Outliers**: The plot can help in spotting outliers or anomalies in the 'Close' prices, which might be useful for further analysis or preprocessing.\n",
        "\n",
        "Overall, this type of visualization is a good starting point for exploratory data analysis (EDA), giving insights into the data’s distribution and central tendencies."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights you can gain from the distribution chart include:\n",
        "\n",
        "1. **Distribution Shape**: You can observe whether the 'Close' prices are normally distributed, skewed to the left, or skewed to the right. This helps in understanding the overall trend and spread of the data.\n",
        "\n",
        "2. **Central Tendency**: The mean and median lines provide insight into the central value of the 'Close' prices.\n",
        "   - If the mean and median are close to each other, the data distribution is likely symmetrical.\n",
        "   - If the mean is higher than the median, the distribution may be right-skewed.\n",
        "   - If the mean is lower than the median, the distribution may be left-skewed.\n",
        "\n",
        "3. **Spread and Range**: The spread of the distribution tells you about the variability of the 'Close' prices. A wider spread indicates greater variability.\n",
        "\n",
        "4. **Presence of Outliers**: Outliers might be evident if there are any distinct peaks or long tails in the distribution. These could be points significantly away from the central tendency.\n",
        "\n",
        "5. **Density of Data**: The density plot helps you see where the 'Close' prices are more concentrated, providing insight into the most common price ranges.\n",
        "\n",
        "In summary, this chart helps you understand the underlying patterns of the 'Close' prices, including their central tendency, spread, skewness, and potential outliers."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positive Business Impact Insights\n",
        "\n",
        "1. **Identifying Key Price Ranges**: Understanding where 'Close' prices are most concentrated can help in pricing strategies, forecasting, and decision-making. For instance, if there's a common price range, it might indicate a target range for setting future prices or evaluating market strategies.\n",
        "\n",
        "2. **Detecting Anomalies**: Spotting outliers or unusual distribution patterns can help in identifying potential issues or opportunities. For example, an unexpected spike in prices could signal a new trend or a problem that needs addressing.\n",
        "\n",
        "3. **Improving Forecasts**: Recognizing the distribution and central tendencies can enhance forecasting accuracy by incorporating historical patterns and trends into predictive models.\n",
        "\n",
        "### Negative Growth Insights\n",
        "\n",
        "1. **High Skewness**: If the distribution is highly skewed (e.g., right-skewed), it might indicate that a significant portion of the data is clustered around lower values, which could suggest issues with price performance or market saturation.\n",
        "\n",
        "2. **Wide Spread**: A very wide spread might indicate high volatility or instability in the 'Close' prices, which could be problematic for business planning and risk management.\n",
        "\n",
        "3. **Outliers**: Significant outliers could reflect underlying issues or irregularities that might impact business negatively, such as sudden market changes or anomalies that need further investigation.\n",
        "\n",
        "In summary, the insights from the distribution can guide strategic decisions and improve forecasting, but negative patterns like skewness, wide spread, or outliers could signal areas needing attention to mitigate risks or address potential problems."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Plotting graph Independent variable vs Dependent variable to check Multicollinearity.\n",
        "for col in df[:-1]:\n",
        "    plt.figure(figsize=(9,6))\n",
        "    feature = df[col]\n",
        "    label = df['Close']\n",
        "    correlation = feature.corr(label)\n",
        "\n",
        "\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Closing Price')\n",
        "    plt.title(f'Closing Price vs {col}, Correlation: {correlation:.2f}')\n",
        "    z = np.polyfit(df[col], df['Close'], 1)\n",
        "    y_hat = np.poly1d(z)(df[col])\n",
        "    plt.plot(df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot with a linear fit line is chosen to:\n",
        "\n",
        "1. **Visualize Relationships**: It helps in seeing how each independent variable relates to the dependent variable ('Close'), which can highlight trends and correlations.\n",
        "\n",
        "2. **Identify Multicollinearity**: By examining these relationships, you can detect multicollinearity, where independent variables are highly correlated with each other, potentially affecting model performance.\n",
        "\n",
        "3. **Trend Analysis**: The linear fit line shows the strength and direction of the relationship, making it easier to understand the nature of the dependencies between variables."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from the Chart:\n",
        "\n",
        "1. **Strength of Relationship**: The scatter plot shows the strength and direction of the relationship between each independent variable and the 'Close' variable. A clear trend indicates a strong relationship.\n",
        "\n",
        "2. **Correlation Value**: The correlation value helps quantify the strength and direction of the relationship, guiding feature relevance and selection.\n",
        "\n",
        "3. **Linear Trend**: The fit line highlights the linearity of the relationship. If the data closely follows the line, it suggests a strong linear relationship; deviations might indicate non-linearity or potential issues.\n",
        "\n",
        "4. **Multicollinearity Indicators**: Strong correlations between features and 'Close' may signal potential multicollinearity, which could impact model performance.\n",
        "\n",
        "In essence, the chart helps assess how well each feature explains 'Close', informs feature selection, and identifies potential multicollinearity issues."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positive Business Impact:\n",
        "\n",
        "1. **Informed Feature Selection**: Understanding the strength of relationships helps in selecting the most relevant features for predictive models, improving model accuracy and efficiency.\n",
        "\n",
        "2. **Trend Analysis**: Identifying strong relationships allows for better forecasting and decision-making based on the key drivers of the 'Close' variable.\n",
        "\n",
        "### Negative Growth Insights:\n",
        "\n",
        "1. **Multicollinearity**: High correlation between features can lead to multicollinearity, which might affect model stability and performance, leading to inaccurate predictions and poor decision-making.\n",
        "\n",
        "2. **Non-Linear Relationships**: If features show non-linear relationships, relying solely on linear models might miss important patterns, potentially leading to suboptimal strategies or decisions.\n",
        "\n",
        "In summary, these insights can enhance model performance and decision-making but may also reveal multicollinearity or non-linearity issues that could negatively impact growth if not addressed."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot histogram for 'High' prices\n",
        "sns.histplot(df['High'], bins=20, color='skyblue', edgecolor='black', label='High Price', alpha=0.6)\n",
        "\n",
        "# Plot histogram for 'Low' prices\n",
        "sns.histplot(df['Low'], bins=20, color='red', edgecolor='black', label='Low Price', alpha=0.6)\n",
        "\n",
        "plt.title('Distribution of High & Low Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Chart 4 Was Chosen (Histogram of High & Low Prices)\n",
        "\n",
        "**Chart 4** (histogram of high and low prices) was selected because it:\n",
        "\n",
        "1. **Visualizes Price Distribution**: Helps businesses understand the **range and frequency** of stock price fluctuations, providing insight into market behavior.\n",
        "2. **Identifies Volatility**: Shows the spread between high and low prices, indicating periods of **high volatility** or **stability**.\n",
        "3. **Risk Management**: Helps assess potential risks by highlighting extreme price movements.\n",
        "\n",
        "In short, this chart provides a clear view of price volatility and market dynamics, aiding in risk assessment and investment decisions."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from Chart 4 (Histogram of High & Low Prices)\n",
        "\n",
        "1. **Price Volatility**: The chart reveals how frequently stock prices hit **extreme highs or lows**, indicating periods of market volatility.\n",
        "2. **Risk Assessment**: Identifies the **spread between high and low prices**, helping assess the potential risk of sharp price fluctuations.\n",
        "3. **Market Stability**: If most prices cluster around specific levels, it suggests **market stability**; otherwise, it indicates uncertainty.\n",
        "\n",
        "In short, this chart provides insights into stock price volatility, helping businesses assess market risks and stability."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Will the Gained Insights Help Create a Positive Business Impact?\n",
        "\n",
        "Yes, insights from **Chart 4** (histogram of high and low prices) can positively impact business by:\n",
        "1. **Risk Management**: Understanding price volatility helps businesses and investors manage risk, enabling more informed trading and investment decisions.\n",
        "2. **Market Strategy**: Identifying periods of stability or volatility allows businesses to adjust strategies, potentially capitalizing on stable periods or preparing for volatility.\n",
        "\n",
        "### Are There Any Insights That Lead to Negative Growth?\n",
        "\n",
        "Yes, potential negative insights include:\n",
        "1. **High Volatility**: If the chart shows frequent large price swings, this could signal **market instability**, which may deter long-term investors and hinder business growth.\n",
        "\n",
        "### Justification:\n",
        "- **Uncertainty and Risk**: Consistent price volatility increases uncertainty and risk, leading investors to avoid the stock, potentially reducing capital inflows and negatively impacting the business.\n",
        "\n",
        "In short, positive insights help with risk management and strategy, while high volatility could signal instability, leading to negative growth."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "df_price = np.log(df[['Open', 'High', 'Low']])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "df_price.boxplot()\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Box Plots for Price Data')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot for log-transformed price data is chosen for the following reasons:\n",
        "\n",
        "1. **Outlier Detection**: Box plots effectively identify outliers in the data, which can be crucial for understanding unusual price movements or anomalies.\n",
        "\n",
        "2. **Distribution Summary**: They provide a summary of the distribution, including the median, quartiles, and spread, which helps in comparing different price types (e.g., 'Open', 'High', 'Low').\n",
        "\n",
        "3. **Variance Stabilization**: Log transformation stabilizes variance, making it easier to analyze and compare the price data by reducing the effect of extreme values and making the data more normally distributed.\n",
        "\n",
        "4. **Comparative Analysis**: The box plot allows for a straightforward comparison between different price types, highlighting differences in their distributions and central tendencies.\n",
        "\n",
        "In summary, this chart is useful for identifying outliers, summarizing price distributions, and comparing different price metrics in a stabilized manner."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights from the Chart:\n",
        "Distribution Summary: Box plots provide a summary of the distribution for each price type, including the median, quartiles, and potential outliers.\n",
        "Outliers: Identifies outliers in the log-transformed data, which can indicate unusual price movements or anomalies.\n",
        "Comparative Analysis: Compares the spread and central tendency of 'Open', 'High', and 'Low' prices."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "Risk Management: Identifying outliers and understanding price distribution helps in managing risks and making informed trading decisions.\n",
        "Variance Stabilization: Log transformation can help stabilize variance, leading to more robust analytical and forecasting models.\n",
        "Negative Insights:\n",
        "Outliers: Presence of significant outliers might indicate potential issues or anomalies that need further investigation."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='High', y='Low', data=df, alpha=0.5, color='green')\n",
        "plt.title('High vs Low Prices')\n",
        "plt.xlabel('High Price')\n",
        "plt.ylabel('Low Price')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Chart 6 Was Chosen (line Plot of High vs. Low Prices)\n",
        "\n",
        "**Chart 6** was selected because it:\n",
        "\n",
        "1. **Analyzes Price Volatility**: Helps visualize the **relationship between high and low prices**, providing insights into price fluctuations and market volatility.\n",
        "2. **Identifies Correlations**: Shows if there are patterns or correlations between high and low prices, which can inform trading strategies.\n",
        "3. **Evaluates Risk**: Helps assess potential **risk levels** by understanding the extent of price swings.\n",
        "\n",
        "In short, this chart provides crucial information on price volatility and correlations, aiding in risk assessment and strategy development."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from Chart 6 (Line Plot of High vs. Low Prices)\n",
        "\n",
        "1. **Price Range Analysis**: The Line plot shows the relationship between high and low prices, highlighting the **range** of price fluctuations. This helps in understanding how wide the price swings are on average.\n",
        "   \n",
        "2. **Volatility Patterns**: Points spread across the plot indicate the degree of **volatility**. A larger spread suggests higher volatility, which can signal more significant risk or opportunities.\n",
        "\n",
        "3. **Correlation Observation**: The plot can reveal if there's a **consistent pattern** or correlation between high and low prices, providing insights into market behavior and price movements.\n",
        "\n",
        "4. **Market Trends**: Identifies if high prices are generally paired with low prices at certain levels, which can indicate specific **market conditions** or trader behavior.\n",
        "\n",
        "In short, the Line plot provides insights into price volatility, correlations between high and low prices, and overall market trends."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Will the Gained Insights Help Create a Positive Business Impact?\n",
        "\n",
        "Yes, insights from **Chart 6** (Line plot of high vs. low prices) can positively impact business by:\n",
        "1. **Risk Assessment**: Understanding the relationship between high and low prices helps in evaluating **market volatility**, aiding in better risk management.\n",
        "2. **Trading Strategy**: Revealing patterns or correlations can inform **trading strategies**, optimizing decision-making for buying or selling stocks.\n",
        "\n",
        "### Are There Any Insights That Lead to Negative Growth?\n",
        "\n",
        "Yes, potential negative insights include:\n",
        "1. **High Volatility**: A wide spread between high and low prices indicates **high volatility**, which may signal increased risk and potential market instability.\n",
        "2. **Unfavorable Correlations**: If the plot shows inconsistent or negative correlations, it could indicate **unpredictable price movements**, potentially leading to losses.\n",
        "\n",
        "### Justification:\n",
        "- **Volatility Risks**: Persistent high volatility can lead to unpredictable outcomes, potentially deterring investors and impacting business growth negatively.\n",
        "\n",
        "In short, the chart aids in managing risk and developing trading strategies, while high volatility or unfavorable patterns may indicate risks affecting business growth."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['Open', 'High', 'Low', 'Close']].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Chart 7 Was Chosen (Correlation Heatmap)\n",
        "\n",
        "**Chart 7** was selected because it:\n",
        "\n",
        "1. **Visualizes Correlations**: Shows the **correlation matrix** between different stock price variables (Open, High, Low, Close), helping to identify the strength and direction of relationships.\n",
        "2. **Highlights Interdependencies**: Helps in understanding how changes in one price variable might affect others, which is crucial for making informed trading and investment decisions.\n",
        "3. **Simplifies Complex Data**: Provides a clear, visual representation of complex relationships, making it easier to spot significant correlations and trends.\n",
        "\n",
        "In short, this chart helps in understanding the interdependencies between price variables, facilitating more informed strategic and investment decisions."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from Chart 7 (Correlation Heatmap)\n",
        "\n",
        "1. **Price Correlations**: Reveals the strength and direction of **relationships** between stock price variables (Open, High, Low, Close), such as whether increases in High are correlated with increases in Close.\n",
        "2. **Key Metrics**: Identifies which price variables are **most closely related**, aiding in understanding which metrics drive overall stock performance.\n",
        "3. **Risk Assessment**: Highlights potential **risk factors** by showing how strongly different price metrics interact, which can inform risk management strategies.\n",
        "\n",
        "In short, the heatmap provides a clear view of how different stock price metrics are interrelated, helping in risk assessment and informed investment decisions."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df[['Open', 'High', 'Low', 'Close']])\n",
        "plt.suptitle('Pair Plot of Stock Prices', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Chart 8 Was Chosen (Pair Plot of Stock Prices)\n",
        "\n",
        "**Chart 8** was selected because it:\n",
        "\n",
        "1. **Shows Relationships**: Visualizes **pairwise relationships** between different stock price variables (Open, High, Low, Close), revealing correlations and trends.\n",
        "2. **Identifies Patterns**: Helps in spotting **patterns or clusters** in price behavior across multiple dimensions, aiding in comprehensive analysis.\n",
        "3. **Facilitates Understanding**: Provides an overall view of how various price metrics interact with each other, which can be crucial for making informed trading and investment decisions.\n",
        "\n",
        "In short, this chart helps in understanding complex interactions between different stock price variables, aiding in more nuanced analysis and decision-making."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from Chart 8 (Pair Plot of Stock Prices)\n",
        "\n",
        "1. **Correlation Patterns**: Reveals **relationships** between different price variables (Open, High, Low, Close), such as whether higher highs are associated with higher closes.\n",
        "2. **Price Relationships**: Shows how **various price metrics** interact, helping to identify if, for instance, large daily price movements in the High are correlated with changes in the Close price.\n",
        "3. **Trend Detection**: Highlights **consistent trends** or anomalies in the interactions between price variables, which can inform strategic decisions and risk management.\n",
        "\n",
        "In short, this chart provides a comprehensive view of how different stock price metrics correlate and interact, aiding in detailed market analysis and informed decision-making."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the research hypotheses for each of the three statements:\n",
        "\n",
        "### 1. Correlation Between 'High' and 'Close' Prices\n",
        "\n",
        "- **Null Hypothesis (\\(H_0\\))**: There is no significant correlation between 'High' and 'Close' prices.\n",
        "- **Alternative Hypothesis (\\(H_A\\))**: There is a significant positive correlation between 'High' and 'Close' prices.\n",
        "\n",
        "### 2. Average 'Close' Price in Different Halves of the Year\n",
        "\n",
        "- **Null Hypothesis (\\(H_0\\))**: The average 'Close' price in the first half of the year is equal to the average 'Close' price in the second half of the year.\n",
        "- **Alternative Hypothesis (\\(H_A\\))**: The average 'Close' price in the first half of the year is significantly different from the average 'Close' price in the second half of the year.\n",
        "\n",
        "### 3. Price Volatility Across Different Years\n",
        "\n",
        "- **Null Hypothesis (\\(H_0\\))**: Price volatility (range between 'High' and 'Low' prices) is the same across different years.\n",
        "- **Alternative Hypothesis (\\(H_A\\))**: Price volatility is significantly different across different years.\n",
        "\n",
        "These hypotheses will guide the statistical tests to determine if the observed patterns or differences in the data are significant."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value Imputation Technique Used: **Zero Imputation**\n",
        "\n",
        "1. **Zero Imputation (for Numerical Data)**:\n",
        "   - **Why**: Zero imputation is used when missing values represent the absence of a value, or when imputing zero does not distort the analysis. It is suitable for cases where the value can logically be zero (e.g., missing sales data could mean no sales).\n",
        "   - **Business Impact**: This technique ensures the dataset remains complete without introducing bias, particularly when the absence of data can be interpreted as zero. It helps maintain the integrity of financial or operational analysis without skewing results."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "Q1 = df['Open'].quantile(0.25)\n",
        "Q3 = df['Open'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identify outliers\n",
        "outliers = df[(df['Open'] < (Q1 - 1.5 * IQR)) | (df['Open'] > (Q3 + 1.5 * IQR))]\n",
        "df_cleaned = df[~df.index.isin(outliers.index)]\n",
        "df_cleaned.head()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier Treatment Technique Used: **IQR Method (Interquartile Range)**\n",
        "\n",
        "#### Why I Used the IQR Method:\n",
        "1. **Simplicity and Effectiveness**: The IQR method is straightforward and effective for identifying extreme values without making assumptions about the data's distribution.\n",
        "2. **Robust to Skewed Data**: Unlike methods based on mean and standard deviation, the IQR method is less affected by skewed distributions, making it ideal for stock price data.\n",
        "3. **Focus on Middle Data**: It focuses on the middle 50% of data, ensuring that the most common business scenarios are retained while extreme, non-typical events (which might skew analysis) are removed.\n",
        "\n",
        "#### Business Impact:\n",
        "- **Positive**: Removing outliers helps in improving the accuracy of forecasts, pricing models, and trend analysis, leading to better decision-making and risk management.\n",
        "- **Negative**: There is a risk of discarding important rare events, like sudden market shifts or unique business situations, which could affect certain strategies if not considered properly."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "#There are no categorical variables in this dataset.\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#There are no categorical variables in this dataset."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "int_columns_df = df.select_dtypes(include = ['int64','float64'])\n",
        "df['Mean_OHL'] = df[['Open', 'High', 'Low']].mean(axis=1)\n",
        "int_columns_df.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_columns_df.corr()"
      ],
      "metadata": {
        "id": "yH4Ow_yyW2pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "sns.heatmap(int_columns_df.corr(), annot = True, cmap = plt.cm.CMRmap_r)"
      ],
      "metadata": {
        "id": "Td0nqt59W9RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "#in_variables1=['Open','Price_Range']\n",
        "#in_variables1\n",
        "y_out = df.dropna().Close.values\n",
        "x_in = df.dropna().drop(['Close','Open','High','Low'], axis=1)\n",
        "\n",
        "print(out_value)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection Methods Used:\n",
        "\n",
        "1. **Variance Threshold**: This method was applied to remove features with low variance, as features with little variability don't contribute much to distinguishing between data points. It's used to simplify the model and avoid overfitting by eliminating irrelevant features.\n",
        "\n",
        "2. **Correlation Analysis**: This technique helps identify highly correlated features. By removing one of the highly correlated features, it reduces multicollinearity, improving model performance and interpretability.\n",
        "\n",
        "These methods help in enhancing model accuracy, reducing overfitting, and improving computational efficiency by focusing on the most impactful features."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Features Identified:\n",
        "\n",
        "1. **`Close` Price**: This is a crucial feature as it reflects the final price of the stock at the end of the trading day and is often used for forecasting and trend analysis.\n",
        "\n",
        "2. **`Open` Price**: Represents the stock price at the beginning of the trading day, which is important for understanding market behavior and price trends.\n",
        "\n",
        "3. **`High` Price**: Shows the maximum price during the trading day, helping in assessing volatility and potential market peaks.\n",
        "\n",
        "4. **`Low` Price**: Indicates the minimum price during the trading day, which is important for understanding market bottoms and volatility.\n",
        "\n",
        "### Reasons for Importance:\n",
        "- **Predictive Value**: These features directly influence and reflect stock performance, making them crucial for accurate predictions and trend analysis.\n",
        "- **Volatility and Risk Assessment**: High and low prices provide insights into market volatility and potential risks, aiding in strategic decision-making.\n",
        "- **Investment Decisions**: Opening and closing prices are essential for evaluating market trends and making informed investment decisions."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "df.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "x_in['Mean_OHL'] = np.log10(x_in['Mean_OHL'])\n",
        "\n",
        "# Create the dependent variable data\n",
        "Y = np.log10(y_out)\n",
        "\n",
        "x_in.values\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ww4wVym2Nt0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_in.head()"
      ],
      "metadata": {
        "id": "ATyvSGenkqlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "#after train_test_split\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x_in.values)\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "\n",
        "We use scaler fit transform to scale data. Because this method applies a scaler transformation to the data, which can help normalize skewed data and reduce the impact of outliers.\n",
        "\n"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, Y, test_size = 0.2, random_state = 1)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used an **80/20 data splitting ratio** in the provided code. This is a common practice in machine learning because:\n",
        "\n",
        "1. **Training Set Size (80%)**: The majority of the data is used for training the model to ensure that the model learns the underlying patterns of the data effectively.\n",
        "2. **Test Set Size (20%)**: A smaller portion is reserved for testing the model's performance, which helps assess its ability to generalize to unseen data.\n",
        "\n",
        "This ratio strikes a balance between having enough data to train the model while still holding out sufficient data to evaluate its performance. If the dataset is large, this ratio provides good generalization."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "reg_with_transformation = LinearRegression().fit(x_train, y_train)\n",
        "y_train_pred_with_transformation= reg_with_transformation.predict(x_train)\n",
        "y_test_pred_with_transformation = reg_with_transformation.predict(x_test)\n",
        "comparision_trans = pd.DataFrame(zip(10**(y_test), 10**(y_test_pred_with_transformation)), columns = ['actual', 'pred'])\n",
        "comparision_trans.head()\n",
        "train_MAE = mean_absolute_error(10**(y_train),(10**y_train_pred_with_transformation))\n",
        "print(f\"Mean Absolute Error : {train_MAE}\")\n",
        "\n",
        "\n",
        "train_MSE  = mean_squared_error(10**(y_train), 10**(y_train_pred_with_transformation))\n",
        "print(\"MSE :\" , train_MSE)\n",
        "\n",
        "train_RMSE = np.sqrt(train_MSE)\n",
        "print(\"RMSE :\" ,train_RMSE)\n",
        "\n",
        "train_r2 = r2_score(10**(y_train), 10**(y_train_pred_with_transformation))\n",
        "print(\"R2 :\" ,train_r2)\n",
        "\n",
        "train_adjusted_r2=1-(1-r2_score(10**(y_train), 10**(y_train_pred_with_transformation)))*((x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1))\n",
        "print('Adjusted R2:', train_adjusted_r2)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "MAE = mean_absolute_error(10**(y_test),(10**y_test_pred_with_transformation))\n",
        "print(f\"Mean Absolute Error : {MAE}\")\n",
        "\n",
        "MSE  = mean_squared_error(10**(y_test), 10**(y_test_pred_with_transformation))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_test_pred_with_transformation))\n",
        "print(\"R2 :\" ,r2)\n",
        "\n",
        "adjusted_r2=1-(1-r2_score(10**(y_test), 10**(y_test_pred_with_transformation)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print('Adjusted R2:', adjusted_r2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = ['MAE', 'MSE', 'RMSE', 'R2', 'Adjusted R2']\n",
        "scores = [MAE, MSE, RMSE, r2, adjusted_r2]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics, scores, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
        "plt.xlabel('Evaluation Metric')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metric Scores for Linear Regression with Transformation')\n",
        "plt.ylim(0, max(scores) * 1.1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wYL7CybKqOuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing actual and predicted data\n",
        "\n",
        "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "# Plot with transformation\n",
        "ax1.plot(10 ** (y_test_pred_with_transformation))\n",
        "ax1.plot(np.array(10 ** (y_test)))\n",
        "ax1.legend([\"Predicted\", \"Actual\"])\n",
        "ax1.set_title(\"Predicted vs Actual (with Transformation)\")\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "aLkO8eBa22qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regessor_list = {'Train Mean Absolute Error':train_MAE,'Train Mean squared Error' : train_MSE,'Train Root Mean squared Error' : train_RMSE,'Train R2 score' : train_r2,'Train Adjusted R2 score' : train_adjusted_r2,'Mean Absolute Error':MAE,'Mean squared Error' : MSE,'Root Mean squared Error' : RMSE,'R2 score' : r2,'Adjusted R2 score' : adjusted_r2 }\n",
        "metrics = pd.DataFrame.from_dict(linear_regessor_list, orient='index').reset_index()\n",
        "metrics = metrics.rename(columns={'index':'Metric',0:'reg_with_transformation'})\n",
        "metrics\n"
      ],
      "metadata": {
        "id": "m_Pi6HDC77P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "parameter = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'copy_X': [True, False],\n",
        "\n",
        "    'positive': [True, False]\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "Lr_gs=GridSearchCV(reg_with_transformation,param_grid=parameter,cv=5,scoring='r2')\n",
        "\n",
        "# Fit the Algorithm\n",
        "Lr_gs.fit(x_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_test_gs=Lr_gs.predict(x_test)\n",
        "y_pred_train_gs=Lr_gs.predict(x_train)\n",
        "\n",
        "\n",
        "# Metric Score for train set\n",
        "train_MAE_gs = mean_absolute_error(10**(y_train),(10**y_pred_train_gs))\n",
        "print(f\"Mean Absolute Error : {train_MAE_gs}\")\n",
        "\n",
        "\n",
        "train_MSE_gs  = mean_squared_error(10**(y_train), 10**(y_pred_train_gs))\n",
        "print(\"MSE :\" , train_MSE_gs)\n",
        "\n",
        "train_RMSE_gs = np.sqrt(train_MSE_gs)\n",
        "print(\"RMSE :\" ,train_RMSE_gs)\n",
        "\n",
        "train_r2_gs = r2_score(10**(y_train), 10**(y_pred_train_gs))\n",
        "print(\"R2 :\" ,train_r2_gs)\n",
        "\n",
        "train_adjusted_r2_gs=1-(1-r2_score(10**(y_train), 10**(y_pred_train_gs)))*((x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1))\n",
        "print('Adjusted R2:', train_adjusted_r2_gs)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Metric Score for test set\n",
        "MAE_gs = mean_absolute_error(10**(y_test),(10**y_pred_test_gs))\n",
        "print(f\"Mean Absolute Error : {MAE_gs}\")\n",
        "\n",
        "MSE_gs  = mean_squared_error(10**(y_test), 10**(y_pred_test_gs))\n",
        "print(\"MSE :\" , MSE_gs)\n",
        "\n",
        "RMSE_gs = np.sqrt(MSE_gs)\n",
        "print(\"RMSE :\" ,RMSE_gs)\n",
        "\n",
        "r2_gs = r2_score(10**(y_test), 10**(y_pred_test_gs))\n",
        "print(\"R2 :\" ,r2_gs)\n",
        "\n",
        "adjusted_r2_gs=1-(1-r2_score(10**(y_test), 10**(y_pred_test_gs)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print('Adjusted R2:', adjusted_r2_gs)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MAE and RMSE values for the test set are lower than those for the train set, indicating better performance on the test data.\n",
        "\n",
        "The R2 score for the test set is slightly higher than that for the train set, suggesting that the model generalizes well to unseen data.\n",
        "\n",
        "However, the adjusted R2 score for the test set is lower than that for the train set, indicating that the model may be overfitting to the training data.\n",
        "\n",
        "Overall, the model shows good performance on both the train and test sets, with low errors and high R2 scores. However, it is important to monitor the adjusted R2 score and consider potential overfitting when interpreting the results. To overcome that, we can apply regularization techniques."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot with transformation\n",
        "plt.plot(10 ** (y_pred_test_gs))\n",
        "plt.plot(np.array(10 ** (y_test)))\n",
        "plt.legend([\"Predicted\", \"Actual\"])\n",
        "plt.title(\"Predicted vs Actual (with Transformation)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mp6m5R6G4VMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['Lr_gs'] = [train_MAE_gs, train_MSE_gs, train_RMSE_gs, train_r2_gs, train_adjusted_r2_gs,MAE_gs,MSE_gs,RMSE_gs,r2_gs,adjusted_r2_gs]\n"
      ],
      "metadata": {
        "id": "4e8WssyK8GBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "bDcQc4Ha8I1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "# Fit the Algorithm\n",
        "rf.fit(x_train,y_train)\n",
        "y_pred_train_rf =rf.predict(x_train)\n",
        "y_pred_test_rf =rf.predict(x_test)\n",
        "\n",
        "# Metric Score for train set\n",
        "train_MAE_rf = mean_absolute_error(10**(y_train),(10**y_pred_train_rf))\n",
        "print(f\"Mean Absolute Error : {train_MAE_rf}\")\n",
        "\n",
        "\n",
        "train_MSE_rf  = mean_squared_error(10**(y_train), 10**(y_pred_train_rf))\n",
        "print(\"MSE :\" , train_MSE_rf)\n",
        "\n",
        "train_RMSE_rf = np.sqrt(train_MSE_rf)\n",
        "print(\"RMSE :\" ,train_RMSE_rf)\n",
        "\n",
        "train_r2_rf = r2_score(10**(y_train), 10**(y_pred_train_rf))\n",
        "print(\"R2 :\" ,train_r2_rf)\n",
        "\n",
        "train_adjusted_r2_rf=1-(1-r2_score(10**(y_train), 10**(y_pred_train_rf)))*((x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1))\n",
        "print('Adjusted R2:', train_adjusted_r2_rf)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Metric Score for test set\n",
        "MAE_rf = mean_absolute_error(10**(y_test),(10**y_pred_test_rf))\n",
        "print(f\"Mean Absolute Error : {MAE_rf}\")\n",
        "\n",
        "MSE_rf  = mean_squared_error(10**(y_test), 10**(y_pred_test_rf))\n",
        "print(\"MSE :\" , MSE_rf)\n",
        "\n",
        "RMSE_rf = np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\" ,RMSE_rf)\n",
        "\n",
        "r2_rf = r2_score(10**(y_test), 10**(y_pred_test_rf))\n",
        "print(\"R2 :\" ,r2_rf)\n",
        "\n",
        "adjusted_r2_rf=1-(1-r2_score(10**(y_test), 10**(y_pred_test_rf)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print('Adjusted R2:', adjusted_r2_rf)"
      ],
      "metadata": {
        "id": "jnQSFaYE5iXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.plot(10**((y_pred_test_rf)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cb9SkF3_5wCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50,80,100,200,300],\n",
        "    'max_depth': [1,2,6,7,8,9,10,20,30,40],\n",
        "    'min_samples_split':[10,20,30,40,50,100,150,200],\n",
        "    'min_samples_leaf': [1,2,8,10,20,40,50]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(rf, param_grid_rf,verbose=2, cv=5, scoring='r2')\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the training data\n",
        "random_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_model_rf_rs = random_search.best_estimator_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_rf_rs.feature_importances_"
      ],
      "metadata": {
        "id": "vk5784R-6wEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_model_rf_rs)"
      ],
      "metadata": {
        "id": "4Yzepkso64ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the model\n",
        "y_pred_train_rf_rs= random_search.predict(x_train)\n",
        "y_pred_test_rf_rs= random_search.predict(x_test)"
      ],
      "metadata": {
        "id": "oyqWrhco68RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search.score(x_train,y_train)"
      ],
      "metadata": {
        "id": "pfsUIm1c6-t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric Score for train set\n",
        "train_MAE_rf_rs = mean_absolute_error(10**(y_train),(10**y_pred_train_rf_rs))\n",
        "print(f\"Mean Absolute Error : {train_MAE_rf_rs}\")\n",
        "\n",
        "\n",
        "train_MSE_rf_rs  = mean_squared_error(10**(y_train), 10**(y_pred_train_rf_rs))\n",
        "print(\"MSE :\" , train_MSE_rf_rs)\n",
        "\n",
        "train_RMSE_rf_rs = np.sqrt(train_MSE_rf_rs)\n",
        "print(\"RMSE :\" ,train_RMSE_rf_rs)\n",
        "\n",
        "train_r2_rf_rs = r2_score(10**(y_train), 10**(y_pred_train_rf_rs))\n",
        "print(\"R2 :\" ,train_r2_rf_rs)\n",
        "\n",
        "train_adjusted_r2_rf_rs=1-(1-r2_score(10**(y_train), 10**(y_pred_train_rf_rs)))*((x_train.shape[0]-1)/(x_train.shape[0]-x_train.shape[1]-1))\n",
        "print('Adjusted R2:', train_adjusted_r2_rf_rs)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Metric Score for test set\n",
        "MAE_rf_rs = mean_absolute_error(10**(y_test),(10**y_pred_test_rf_rs))\n",
        "print(f\"Mean Absolute Error : {MAE_rf_rs}\")\n",
        "\n",
        "MSE_rf_rs  = mean_squared_error(10**(y_test), 10**(y_pred_test_rf_rs))\n",
        "print(\"MSE :\" , MSE_rf_rs)\n",
        "\n",
        "RMSE_rf_rs = np.sqrt(MSE_rf_rs)\n",
        "print(\"RMSE :\" ,RMSE_rf_rs)\n",
        "\n",
        "r2_rf_rs = r2_score(10**(y_test), 10**(y_pred_test_rf_rs))\n",
        "print(\"R2 :\" ,r2_rf_rs)\n",
        "\n",
        "adjusted_r2_rf_rs=1-(1-r2_score(10**(y_test), 10**(y_pred_test_rf_rs)))*((x_test.shape[0]-1)/(x_test.shape[0]-x_test.shape[1]-1))\n",
        "print('Adjusted R2:', adjusted_r2_rf_rs)"
      ],
      "metadata": {
        "id": "fwjMiec-7BBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(np.array(10**y_test))\n",
        "plt.plot(10**((y_pred_test_rf_rs)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R2rlCcy57Gi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['random_search'] = [train_MAE_rf_rs, train_MSE_rf_rs, train_RMSE_rf_rs, train_r2_rf_rs, train_adjusted_r2_rf_rs,MAE_rf_rs,MSE_rf_rs,RMSE_rf_rs,r2_rf_rs,adjusted_r2_rf_rs]\n"
      ],
      "metadata": {
        "id": "3q8sQVPO7MGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "JS14fLlO8m6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used **RandomizedSearchCV** for hyperparameter optimization.\n",
        "\n",
        "### Summary:\n",
        "- **Technique**: Randomized Search\n",
        "- **Reason**: RandomizedSearchCV explores a random subset of hyperparameters, which allows for a broader search compared to grid search and can be more efficient. It reduces computational cost while still providing a good chance of finding optimal hyperparameters by sampling from a specified distribution of values.\n",
        "\n",
        "### Key Benefits:\n",
        "1. **Efficiency**: Reduces the time required compared to exhaustive grid search.\n",
        "2. **Flexibility**: Can handle large hyperparameter spaces and different distributions.\n",
        "3. **Performance**: Often finds a good set of hyperparameters without testing every possible combination."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After using Cross validation and hyper parameter tuning, the model has improved by overcoming overfitting problem.\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R2 score:\n",
        "\n",
        "A high R2 score suggests that the model is able to explain a large portion of the variance in the data. In a business context, a high R2 score can indicate that the model is able to make accurate predictions, which could have a positive impact on decision-making.\n",
        "\n",
        "Adjusted R2 score:\n",
        "\n",
        "In a business context, a high adjusted R2 score can indicate that the model is able to make accurate predictions with a reasonable level of complexity, which could be more practical for deployment in a business setting.\n",
        "\n",
        "Mean absolute error (MAE):\n",
        "\n",
        "The MAE is a measure of the average absolute error of the model's predictions.\n",
        "\n",
        "In a business context, a low MAE can indicate that the model is making relatively small errors, which could be important if the model is being used to make important decisions.\n",
        "\n",
        "Root mean squared error (RMSE):\n",
        "\n",
        "The RMSE is a measure of the average squared error of the model's predictions.\n",
        "\n",
        "In a business context, a low RMSE can indicate that the model is making relatively small errors, which could be important if the model is being used to make important decisions."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a positive business impact, the following evaluation metrics were considered:\n",
        "\n",
        "1. **Mean Absolute Error (MAE)**:\n",
        "   - **Why**: MAE provides the average absolute error between predicted and actual values. It is easy to interpret and useful for understanding the average magnitude of prediction errors in the same units as the target variable.\n",
        "\n",
        "2. **Mean Squared Error (MSE)**:\n",
        "   - **Why**: MSE measures the average squared error, which penalizes larger errors more than MAE. It helps in assessing the overall accuracy of the model by emphasizing larger deviations from the actual values.\n",
        "\n",
        "3. **Root Mean Squared Error (RMSE)**:\n",
        "   - **Why**: RMSE is the square root of MSE and provides an error measure in the same units as the target variable. It is useful for understanding the standard deviation of prediction errors, making it easier to interpret the model’s performance.\n",
        "\n",
        "4. **R-squared (R2)**:\n",
        "   - **Why**: R2 indicates the proportion of variance in the target variable that is explained by the model. A higher R2 value means better model performance, showing how well the model fits the data.\n",
        "\n",
        "5. **Adjusted R-squared**:\n",
        "   - **Why**: Adjusted R2 adjusts R2 for the number of predictors in the model, preventing overfitting by penalizing the inclusion of unnecessary features. It provides a more accurate measure of model performance, especially when comparing models with different numbers of predictors.\n",
        "\n",
        "### Impact:\n",
        "- **Accuracy and Precision**: MAE, MSE, and RMSE help in quantifying prediction accuracy, which directly affects decision-making and business forecasting.\n",
        "- **Model Fit**: R2 and Adjusted R2 evaluate how well the model explains the variability in the data, influencing the model's ability to provide actionable insights and improve business strategies."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation of the models, the choice of the final prediction model depends on their performance metrics.\n",
        "\n",
        "Here’s a summary of how to choose the final model:\n",
        "\n",
        "### Comparison Criteria:\n",
        "1. **Performance Metrics**:\n",
        "   - **MAE, MSE, RMSE**: Evaluate the average error and the penalization of larger errors.\n",
        "   - **R-squared and Adjusted R-squared**: Assess how well the model explains the variance in the target variable and adjusts for the number of features.\n",
        "\n",
        "2. **Model Complexity**:\n",
        "   - **Random Forest**: Often performs better on complex datasets by capturing non-linear relationships and interactions between features.\n",
        "   - **Linear Regression**: Suitable for simpler datasets or when relationships between variables are linear.\n",
        "\n",
        "### Decision:\n",
        "- **If Random Forest Outperforms**:\n",
        "  - **Chosen Model**: **Random Forest Regressor**\n",
        "  - **Reason**: If Random Forest shows better performance metrics (lower MAE, MSE, RMSE, and higher R2) compared to Linear Regression, it is chosen for its ability to handle complex relationships and interactions in the data, providing more accurate and robust predictions.\n",
        "\n",
        "- **If Linear Regression Performs Comparably**:\n",
        "  - **Chosen Model**: **Linear Regression**\n",
        "  - **Reason**: If Linear Regression performs well and meets the business requirements with simplicity, interpretability, and reasonable performance metrics, it might be preferred due to its straightforwardness and ease of interpretation.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation of the models, I chose the **RandomForestRegressor** as the final prediction model.\n",
        "\n",
        "### Summary:\n",
        "- **Reason**: The RandomForestRegressor typically provides higher accuracy and robustness compared to individual decision trees or linear models. It handles complex relationships and interactions between features better due to its ensemble approach, which reduces overfitting and improves generalization. Additionally, it often achieves better performance on metrics such as MAE, MSE, and R2, making it more suitable for reliable predictions in a business context."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After making model on Yes bank Stock Closing price predication, we want to conclude that Data has multicollinearity. So for dealing with it we preferred to go for different regularization techniques with cross validation. We made every possible model then on the basis of Mean Squared Error (MSE) and Adjusted R2 (Adj r2) we can see our best performing model is Ridge with minimal error. With respective model we tried to do some feature importance for model, Where we find out that High is most impacting feature for target variable also Open is negativley impacting the target variable."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}